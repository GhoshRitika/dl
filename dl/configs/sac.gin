# Hyperparameters from Minh et al. 2015: https://www.nature.com/articles/nature14236
import dl.util.gin_torch_externals
import dl.trainer
import dl.util

optim.Adam.betas = (0.9, 0.999)

SAC.env_fn = @atari_env
SAC.optimizer = @optim.Adam
SAC.policy_lr = 3e-4
SAC.qf_lr = 3e-4
SAC.vf_lr = 3e-4
SAC.gamma = 0.99
SAC.batch_size = 32
SAC.frame_stack = 4
SAC.eval_nepisodes = 100
SAC.update_period = 1
SAC.target_update_period = 1
SAC.policy_update_period = 1
SAC.buffer_size = 1000000
SAC.learning_starts = 50000
SAC.target_smoothing_coef = 0.005
SAC.automatic_entropy_tuning = True
SAC.reparameterization_trick = True
SAC.target_entropy = None
SAC.reward_scale = 1
SAC.gpu = True # set to False to force cpu

Trainer.maxt = 50000000
Trainer.eval = True
Trainer.eval_period = 1000000
Trainer.save_period = 1000000

Checkpointer.min_ckpt_period = 10000000
Checkpointer.max_ckpts_to_keep = 1

atari_env.game_name = "Pong"
atari_env.sticky_actions = False
atari_env.noop = True
atari_env.seed = 0
atari_env.frameskip = 4
atari_env.episode_life = True
atari_env.clip_rewards = True
