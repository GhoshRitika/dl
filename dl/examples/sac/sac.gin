# Hyperparameters from Soft Actor Critic: https://arxiv.org/abs/1812.05905
import dl.examples.sac

train.Trainer = @SAC

optim.Adam.betas = (0.9, 0.999)

SAC.maxt = 100000
SAC.seed = 0
SAC.eval = True
SAC.eval_period = 10000
SAC.save_period = 10000
SAC.maxseconds = None
SAC.gpu = True

SAC.env_fn = @make_env
SAC.nenv = 1
SAC.norm_observations = True
SAC.eval_num_episodes = 20
SAC.record_num_episodes = 5

SAC.buffer_size = 10000
SAC.frame_stack = 1
SAC.learning_starts = 5000
SAC.update_period = 1

SAC.env_fn = @make_env
SAC.optimizer = @optim.Adam
SAC.batch_size = 128
SAC.policy_lr = 3e-4
SAC.qf_lr = 3e-4
SAC.vf_lr = 3e-4
SAC.policy_mean_reg_weight = 1e-3
SAC.gamma = 0.99
SAC.target_update_period = 1
SAC.policy_update_period = 1
SAC.target_smoothing_coef = 0.001
SAC.automatic_entropy_tuning = True
SAC.reparameterization_trick = True
SAC.target_entropy = None
SAC.reward_scale = 1
SAC.log_period = 100

Checkpointer.ckpt_period = 10000

make_env.env_id = "LunarLanderContinuous-v2"

Policy.base        = @FeedForwardPolicyBase
ValueFunction.base = @FeedForwardVFBase
QFunction.base     = @AppendActionFeedForwardQFBase

TanhDiagGaussian.constant_log_std = False


ObsNorm.steps = 10000
ObsNorm.mean = None
ObsNorm.std = None
ObsNorm.eps = 1e-2
ObsNorm.log = True
ObsNorm.log_prob = 0.01
